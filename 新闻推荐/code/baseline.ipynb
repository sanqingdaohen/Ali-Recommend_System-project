{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e1f4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore') # 忽略警告,防止污染日志\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba341af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\coder\\Desktop\\新闻推荐\\tcdata c:\\Users\\coder\\Desktop\\新闻推荐\\temp_results\n"
     ]
    }
   ],
   "source": [
    "root_path = Path.cwd().parent # 再jupyter里面需要.cwd()找到运行本文件的目录\n",
    "data_path = root_path/'tcdata' # 天池给的原始数据路径\n",
    "save_path = root_path/'temp_results'  # 存储temp数据的路径\n",
    "print(data_path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80ace291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节约内存的一个标配函数\n",
    "def reduce_mem(df):\n",
    "    starttime = time.time() # 程序开始时间\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 #DataFrame 总内存使用量（单位：字节）。\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes #注意df[col].dtypes 一般是 numpy的返回类型\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min() # 找到这一列的最小值\n",
    "            c_max = df[col].max() # 找到这一列的最大值\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue #如果这一列最小值或者最大值是NaN就跳过这一列\n",
    "            if str(col_type)[:3] == 'int': # 如果 是 np.int 类型,根据这列数值区间,尽量减少内存\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else: # 如果 是 np.float 类型,根据这列数值区间,尽量减少内存\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a06904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug模式：从训练集中划出一部分数据来调试代码\n",
    "def get_all_click_sample(data_path, sample_nums=10000):\n",
    "    \"\"\"\n",
    "        训练集中采样一部分数据调试\n",
    "        data_path: 原数据的存储路径\n",
    "        sample_nums: 采样数目（这里由于机器的内存限制，可以采样用户做）\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique() # csv文件中的用户可能有重复的,这个是排除重复的用户\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) # 采集10000个用户,无放回抽样\n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)] # 保留采集的用户数据\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    #删除那些在 'user_id'、'click_article_id' 和 'click_timestamp' 这三列上值完全相同的重复行，仅保留第一次出现的那一条。\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca84c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n",
    "# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\n",
    "def get_all_click_df(data_path, offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path /'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path/'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path/'testA_click_log.csv')\n",
    "\n",
    "        #all_click = trn_click.append(tst_click)\n",
    "        all_click = pd.concat([trn_click, tst_click], ignore_index=True)  #将训练集和测试集拼起来\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    #all_click = all_click.sample(frac=0.1, random_state=42) # 对all_ckick采样,不然数据太对会很耗时间\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "793991f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全量训练集\n",
    "all_click_df = get_all_click_df(data_path, offline=False) # all_click_df里面有100多万训练集和50多万测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a51623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n",
    "# def get_user_item_time(click_df):\n",
    "    \n",
    "#     click_df = click_df.sort_values('click_timestamp')#根据时间戳由低到高排训练集和测试集中的数据\n",
    "    \n",
    "#     def make_item_time_pair(df):\n",
    "#         return list(zip(df['click_article_id'], df['click_timestamp'])) #[(user_id,clik_time),(user_id,clik_time)...]\n",
    "    \n",
    "#     user_item_time_df = click_df.groupby('user_id')[['click_article_id', 'click_timestamp']].apply(lambda x: make_item_time_pair(x))\\\n",
    "#                                                             .reset_index().rename(columns={0: 'item_time_list'})\n",
    "#     user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "#     return user_item_time_dict\n",
    "    \n",
    "\n",
    "def get_user_item_time(click_df):\n",
    "    \"\"\"\n",
    "    返回的每一个用户再不同文章上点击的时间,时间是由小到大\n",
    "    {user_id:[(artikle_id ,time),(artikle_id ,time)...] \n",
    "    user_id:[(artikle_id ,time),(artikle_id ,time)...]\n",
    "    }\"\"\"\n",
    "    # 按时间戳排序，保证行为序列时序正确\n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    # 按用户分组，生成 (article_id, timestamp) 列表\n",
    "    user_item_time_dict = click_df.groupby('user_id').apply(\n",
    "        lambda x: list(zip(x['click_article_id'], x['click_timestamp']))\n",
    "    ).to_dict()\n",
    "    \n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7df6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取近期点击最多的文章\n",
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24dee0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(df):\n",
    "    \"\"\"\n",
    "        文章与文章之间的相似性矩阵计算\n",
    "        :param df: 数据表\n",
    "        :item_created_time_dict:  文章创建时间的字典\n",
    "        return : 文章与文章的相似性矩阵\n",
    "        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n",
    "    \"\"\"\n",
    "    \n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    # 计算物品相似度\n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # 在基于商品的协同过滤优化的时候可以考虑时间因素\n",
    "        for i, i_click_time in item_time_list:\n",
    "            item_cnt[i] += 1    #统计有多少篇文章\n",
    "            i2i_sim.setdefault(i, {}) #如果物品 i 还没有在 i2i_sim 中出现过，就给它初始化一个空字典 {}；如果已经存在，就跳过\n",
    "            for j, j_click_time in item_time_list:\n",
    "                if(i == j):\n",
    "                    continue #排除与自己计算相似度\n",
    "                i2i_sim[i].setdefault(j, 0) \n",
    "                \n",
    "                i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n",
    "                \"\"\"\n",
    "                {'i':{'j':}\n",
    "                }\n",
    "                \"\"\"\n",
    "                \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    # 平常的itemcf 计算相似度就是,喜欢i1物品的用户u1,喜欢i2物品的用户u2\n",
    "    # sim(i1,i2) = (u1 交 u2) / sqrt(u1*u2)\n",
    "\n",
    "    #这个是添加了 加权分数 1/log(N+1) N为单个用户点击的文章,此时i2i_sim = { 1/log(N+1)} / sqrt(u1*u2)\n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(i2i_sim_, open(save_path /'itemcf_i2i_sim.pkl', 'wb'))\n",
    "    \n",
    "    return i2i_sim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc667c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:16<00:00, 15128.80it/s]\n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bc5c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于商品的召回i2i\n",
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n",
    "        :param i2i_sim: 字典，文章相似性矩阵\n",
    "        :param sim_item_topk: 整数， 选择与当前文章最相似的前k篇文章\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "        注意: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    user_hist_items_ = {user_id for user_id, _ in user_hist_items}\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items_:\n",
    "                continue\n",
    "                \n",
    "            item_rank.setdefault(j, 0)\n",
    "            item_rank[j] +=  wij\n",
    "    \n",
    "    # 不足10个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "        \n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ddcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [21:13<00:00, 196.34it/s] \n"
     ]
    }
   ],
   "source": [
    "# 定义\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "\n",
    "# 获取 用户 - 文章 - 点击时间的字典\n",
    "user_item_time_dict = get_user_item_time(all_click_df) \n",
    "\"\"\"\n",
    "返回的每一个用户再不同文章上点击的时间,时间是由小到大\n",
    "    {user_id:[(artikle_id ,time),(artikle_id ,time)...] \n",
    "    user_id:[(artikle_id ,time),(artikle_id ,time)...]\n",
    "\"\"\"\n",
    "\n",
    "# 去取文章相似度\n",
    "i2i_sim = pickle.load(open(save_path /'itemcf_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "# 相似文章的数量\n",
    "sim_item_topk = 10\n",
    "\n",
    "# 召回文章数量\n",
    "recall_item_num = 10\n",
    "\n",
    "# 用户热度补全\n",
    "item_topk_click = get_item_topk_click(all_click_df, k=50)\n",
    "\n",
    "for user in tqdm(all_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, \n",
    "                                                        sim_item_topk, recall_item_num, item_topk_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa2a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:03<00:00, 64162.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将字典的形式转换成df\n",
    "user_item_score_list = []\n",
    "\n",
    "for user, items in tqdm(user_recall_items_dict.items()):\n",
    "    for item, score in items:\n",
    "        user_item_score_list.append([user, item, score])\n",
    "\n",
    "recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01e2ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    #save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    save_name = save_path / f\"{model_name}_{datetime.today().strftime('%m-%d')}.csv\"\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d61293b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取测试集\n",
    "tst_click = pd.read_csv(data_path / 'testA_click_log.csv')\n",
    "tst_users = tst_click['user_id'].unique()\n",
    "\n",
    "# 从所有的召回数据中将测试集中的用户选出来\n",
    "tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n",
    "\n",
    "# 生成提交文件\n",
    "submit(tst_recall, topk=5, model_name='itemcf_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b587ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
